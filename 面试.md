## 面试总结

- MapReudce 为何要排序?

> 很多人的误解在Map阶段，如果不使用Combiner便不会排序，这是错误的，不管你用不用Combiner，Map Task均会对产生的数据排序（如果没有Reduce Task，则不会排序， 实际上Map阶段的排序就是为了减轻Reduce端排序负载）。由于这些排序是MapReduce自动完成的，用户无法控制，因此，在hadoop 1.x中无法避免，也不可以关闭，但hadoop2.x是可以关闭的。 
>
> Map端排序操作的关闭方法：
>
> 配置文件中 ，没有相关的配置项直接关闭排序，但是有配置项 `map.sort.class` 指定了一个排序类 `org.apache.hadoop.util.QuickSort`，即默认为快排， 这个排序类实现了 `org.apache.hadoop.util.IndexedSorter` 接口，这个接口还有一个实现类 `org.apache.hadoop.util.HeapSort` ，即堆排序，但是无法直接指定不执行排序操作，可以自己写一个类，实现 这个接口，但是在实现方法中不做任何操作，然后让配置项指定这个自定义的 排序类，这样就相当于关闭了排序步骤。

- 哪些压缩支持分片  ： bzip2, bzip, lzo
- mapper 的输入分片是怎么做的  !

> https://www.jianshu.com/p/378329c16473
>
> **在MapReduce处理过程中主要分为四个阶段：Split（分片）阶段、Map阶段、Shuffle（混排、重拍）阶段、Reduce阶段。**
>
> Split 阶段在 Appilcation Master 中
>
> Split 过程相关的三个类：`InputSplit.class`、`InputFormat.class` 、`RecordReader.class` 
>
> 1. `InputSplit.class`: Split分片并没有实际的数据，分片其实只是对一个文件进行逻辑上的分片，数据还是按照Block的方式保存在HDFS中，而一个Split分片的主要记录了该分片是从文件的那个位置开始，长度是多少，这些数据的位置在哪里这些信息，在读取分片数据的时候，是根据FileSplit类中的信息去读取相应的Block的数据。这也是为什么分片最好和Block大小相同的原因，如果一个FileSplit的大小大于一个Block的大小，则该分片可能会需要从其他节点的Block读取数据，这样就会造成不必要的网络传输，导致处理时间增长。
> 2. `InputFormat.class`:  实现读取分片的过程， 由两个函数完成，通过getSplit()函数得到对文件的分片信息后，然后读取分片表示的数据，并生成<key,value>键值对送入到map端，而生成<key,value>键值对则是由createRecordReader()函数完成。
> 3. `RecordReader.class` ：当LineRecordReader方法每一次读取一行时，便执行一次nextkeyvalue方法，当成功生成一个<key,value>键值对后，nextkeyvalue方法返回true值，这是新得到的key和value存放在LineRecordReader对象中的key和value属性中，就可以进行读取了。当nextkeyvalue()方法将所有的数据读取结束后，就表示一个split中的所有数据被读取到map中。
>
> getSplit()---->input splits----->createRecordReader----->nextKeyValue()-----><key,value>键值对
>
> 如果要实现自定义的 Split 方式，则实现上面三个类。

- Hadoop文件系统  ：FileSystem、DistributeFileSystem、ClientProtocal、DatanodeProtocal
- NIO Socket 的 epoll、poll
- socket 有哪些函数

> 主要介绍：socket、connect、send、sendto、bind、listen、accept、recv、recvfrom、close、shutdown

- Writable 序列化框架有什么缺点：缺乏语言的可移植性。
- Avro 序列化框架的优点：Avro 是一个独立于编程语言的数据序列化框架，旨在解决 Writable 序列化框架的不足，即缺乏语言的可移植性。Avro数据是用语言无关的模式定义的，Avro模式通常用JSON来写，数据通常采用二进制格式来编码，但也有其他选择。
- HDFS的安全模式：安全模式是HDFS所处的一种特殊状态，在这种状态下，文件系统只接受读数据请求，而不接受删除、修改等变更请求。在NameNode主节点启动时，HDFS首先进入安全模式，DataNode在启动的时候会向namenode 汇报可用的block等状态，当整个系统达到安全标准时，HDFS自动离开安全模式。
- HDFS离开安全模式：1）达到副本数量要求的block比例满足要求； 2）可用的datanode节点数满足配置的数量要求； 3） 1、2 两个条件满足后维持的时间达到配置的要求。

## 字节跳动

三面： 14：00 -- 17：00

### 一面：

算法题：排列组合， 时间复杂度

Mapreduce 执行过程、序列化框架、压缩框架、哪些压缩支持分片、



### 二面：

算法题：

```
盗匪抢劫银行
https://blog.csdn.net/DERRANTCM/article/details/47970775
```

其他：

Mapreduce 为啥排序





### 三面：

算法题1：

```
Start End CPU  

A(1, 10, 5)

B(3, 8,  3)

C(4, 9, 1)

统计任意时刻的CPU的使用数
```

算法题2：

```
原语实现生产者消费者。
```

算法题3：

```
输入一个字符串(i am a ...) , 按照字母出现次数进行排序，对出现次数相同的字母按字母顺序排序。
```

其他问题：

锁有哪些：悲观锁、乐观锁CAS、锁自旋

Socket服务端有哪些函数、哪些是阻塞的，什么是阻塞，NIO中的Socket服务端哪个函数是阻塞的，NIO的 epoll 和 poll函数的区别

HashMap， ArrayList 的底层实现

JVM内存模型，并发， 什么时候 OOM，

B+Tree，索引，



