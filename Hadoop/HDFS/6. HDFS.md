
# 6. HDFS 

## 6.1.  HDFS 概述

### 6.1 HDFS 体系结构

> 主要角色： Client、NameNode、DataNode、SecondaryNameNode

#### 6.1.1 Block

> HDFS 文件存储处理的单元，默认 128M

#### 6.1.2 NameNode & SecondaryNameNode

> NameNode 维护着整个文件系统的文件目录树，文件/目录的元信息和文件的数据块索引，即每个文件对应的数据块列表。这些信息以两种形式保存储在本地文件系统中：FSImage、Edit Log。

> NameNode 中还会保存了数据块所在的数据节点的信息，但是这些数据节点信息不会存储在NameNode的文件系统中。

> SecondaryNameNode 是用于定期合并 FSImage 和 Edit Log 两个文件的。

#### 6.1.3 DataNode

> 存储真实数据

#### 6.1.4 Client

- DistributedFileSystem
- HdfsDataInputStream
- HdfsDataOutputStream


## 6.2. 基于远程过程调用的接口

### 6.2.1 客户端相关接口

#### 6.2.1.1 相关的类

> 数据块相关

- **Block** : 其中含有三个主要成员变量：
    - blockId：数据块的唯一标识，即数据块的ID号
    - numBytes：数据块包含的文件数据大小。
    - generationStamp：数据块的时间戳，用于数据的一致性检查。
- **ExtendedBlock** : 其中含有一个 Block 对象，只是在这个基础之上加了一个 poolId 变量。
- **LocatedBlock** ：其中含有一个 ExtendedBlock 对象，同时还包含以下成员变量：
    - long offset：数据块在对应文件中的偏移量
    - DatanodeInfo[] locs： 数据块所在的数据节点信息， 包含了所有可用的数据块位置
    - boolean corrupt：数据块是否损坏标志
- **LocatedBlocks** ：包含多个 LocatedBlock 对象
- **BlockLocalPathInfo**：应用于 ClientDatanodeProtocol 接口中，用于 HDFS 读取文件的数据节点本地读优化，除了包含  ExtendedBlock 对象，还包含以下两个变量：
    - String localBlockPath：数据块在本地的路径
    - String localMetaPath：数据块校验信息在本地的路径

> 数据节点相关

- **DatanodeID**：用于在HDFS集群中确定一个数据节点，从此对象中可以获得数据节点的主机地址及功能端口号等信息。
- **DatanodeInfo**：继承 DatanodeID， 在此基础之上提供了附加状态信息：容量、已使用容量、剩余容量、状态更新时间、流接口服务线程数、数据节点在集群中的位置、数据节点状态等信息。


#### 6.2.1.2 ClientProtocol

> **ClientProtocol** ： Client 与 NameNode 间的接口，这是 HDFS 客户端访问文件系统的入口。

> 提供了两方面的功能：

- 用于实现 Hadoop 文件系统相关功能的能力（FileSystem）；
- 用于对 HDFS 状态进行查询、设置的能力

##### 6.2.1.2.1 文件/目录元数据部分的操作

> 这部分的操作函数与Hadoop抽象文件系统中相应的方法有着对应关系。

<table>
  <tr>
    <th>Hadoop FileSystem 操作</th>
    <th>ClientProtocol 操作</th>
    <th>描述</th>
  </tr>
  <tr>
    <td>URL.open</br>FileSystem.open</br>FileSystem.create</br>FileSystem.append</td>
    <td>create</br>append</br>getBlockLocations</td>
    <td>打开一个文件</td>
  </tr>
  <tr>
    <td>FSDataInputStream.read</td>
    <td>getBlockLocations</br>reportBadBlocks</td>
    <td>从文件中读取数据</td>
  </tr>
  <tr>
    <td>FSDataOutputStream.write</td>
    <td>addBlock</br>abandonBlock</td>
    <td>向文件中写数据</td>
  </tr>
  <tr>
    <td>FSDataInputStream.close</br>FSDataOutputStream.close</td>
    <td>fsync</br>complete</td>
    <td>关闭一个文件</td>
  </tr>
  <tr>
    <td>FSDataInputStream.seek</td>
    <td>getBlockLocations</td>
    <td>改变文件读写文件</td>
  </tr>
  <tr>
    <td>FileSystem.getFileStatus</br>FileSystem.getyContentSummary</br>FileSystem.get*</td>
    <td>getFileInfo</br>getContentSummary</td>
    <td>获得文件/目录的属性以及使用的存储空间等信息</td>
  </tr>
  <tr>
    <td>FileSystem.set*</td>
    <td>setPermission</br>setOwner</br>setTimes</br>setReplication</td>
    <td>修改文件属性</td>
  </tr>
  <tr>
    <td>FileSystem.createNewFile</td>
    <td>N/A</td>
    <td>创建一个文件</td>
  </tr>
  <tr>
    <td>FileSystem.delete</td>
    <td>delete</td>
    <td>删除文件/目录</td>
  </tr>
  <tr>
    <td>FileSystem.rename</td>
    <td>rename</td>
    <td>更改文件名</td>
  </tr>
  <tr>
    <td>FileSystem.mkdirs</td>
    <td>mkdirs</td>
    <td>创建子目录</td>
  </tr>
  <tr>
    <td>FileSystem.listStatus</td>
    <td>getListing</td>
    <td>读取一个目录下的项目</td>
  </tr>
  <tr>
    <td>FileSystem.setWorkingDirectory</td>
    <td>N/A</td>
    <td></td>
  </tr>
</table>


##### 6.2.1.2.2 写文件相关的操作

- create
- append
- addBlock
- abandonBlock
- fsync：类似 flush，  保证NameNode上对文件元数据的修改会被保存到磁盘，但是不保证写到 DataNode 上的数据的持久化
- complete：类似 close, 和 fsync 一样，此方法只和 NameNode 通信。
- renewLease： 客户端调用此方法，相当于往NameNode发送心跳信息，如果 NameNode 长时间没有收到客户端的租约更新，则认为客户端已经崩溃 NameNode 会试图关闭文件，以防止资源泄露。
- recoverLease：当客户端从崩溃中恢复，并试图继续未完成的写文件操作，则此方法会被调用。

##### 6.2.1.2.3 读文件相关的操作

- getBlockLocatoions
- reportBadBlocks

##### 6.2.1.2.4 工具 dfsadmin 依赖的方法

> 此工具主要由HDFS管理员使用

- setQuota：实现与配额相关的功能
- setSafeMode：设置安全模式
- saveNamespace：把当前内存中的文件系统镜像保持到一个新的fsimage中，并重置日志文件
- metaSave：用于将NameNode中的主要数据结构保存到 Hadoop 日志目录的指定文件中。
- refreshNodes ： 刷新节点，集群可能会新增节点，或者移除节点，需要调用此方法进行刷新节点，此方法无参数，它所需要的信息包含在两个文件中，include文件：用于指定可以连接到NameNode的数据节点列表，exclude文件：用于指定要移除的数据节点
- distributedUpgradeProgress：用于查询升级的进度
- finalizeUpgrade：用于提交升级




#### 6.2.1.3 ClientDatanodeProtocol

> **ClientDatanodeProtocol** ：Client 与 DataNode 之间的接口。只有三个方法：

- recoverBlock：用于 HDFS 客户端的输出流 DFSOutputStream 中，客户端往 DataNode 中写数据的过程中，如果某个副本所在的 DataNode 出现错误，客户端会尝试进行数据块恢复，这时会调用此方法，从正常工作的 DataNode 中找到恢复点，然后才能继续输出数据。
- getBlockInfo：与HDFS一致性模型相关。
- getBlockLocalInfo：与本地读优化相关。

> 一般情况下 客户端与 DataNode 之间主要是通过基于流的接口进行交互的，较少使用上面的这三个方法。




### 6.2.2 服务器间的接口

#### 6.2.2.1 DatanodeProtocol

> DataNode 与 NameNode 间的接口 （DataNode 为IPC客户端，NameNode 为IPC服务端）

##### 6.2.2.1.1 相关类

- **DatanodeRegistration** ： 用于数据节点的注册，继承自 DatanodeID，DatanodeID 类可以唯一确定一个数据节点， DatanodeRegistration 在 DatanodeID 的基础之上增加了几个成员变量：
    - storageInfo：类型为 StorageInfo，保存了数据节点的存储系统信息
    - exportedKeys：用于HDFS的安全性
- **StorageInfo** ：保存了数据节点的存储系统信息，包括三个成员变量：
    - layoutVersion：保存了HDFS存储系统信息结构的版本号
    - namespaceID：存储系统的唯一标识符
    - cTime：该存储系统信息的创建时间
- **NamespaceInfo**：继承自 StorageInfo，其中包含的信息是整个HDFS集群的信息，和具体的数据节点没有关系。其中增加了成员变量：
    - buildVersion：保存了系统构建的版本号
    - blockPoolID

##### 6.2.2.1.2 握手、注册、数据块上传和心跳相关方法

- **versionRequest()** : DataNode 启动时会通过这个函数和 NameNode 先进行握手，其返回值是 NamespaceInfo 对象。 握手时，会检查 NameNode 和 DataNode 的 buildVersion， 如果不相同，则会导致 DataNode 退出。（DataNode 启动时使用）
- **registerDatanode()**：握手成功之后，DataNode 会通过这个方法向 NameNode 注册，注册是 DataNode 投入正常工作前需要进行的必要步骤，其输入参数是 DatanodeRegistration 对象。（DataNode 启动时使用）
- **blockReport()**：注册成功之后， DataNode 通过此方法上报它所管理的全部数据块信息，帮助 NameNode 建立 Block 和 DataNode 的映射关系。（DataNode 启动时使用）
- **sendHeartbeat()** ： DataNode 通过这个方法向 NameNode 发送心跳来报告自己的状态，如果 NameNode 长时间接收不到 DataNode 的心跳，则认为该 DataNode 已经失效。


##### 6.2.2.1.3 DatanodeCommand

> blockReport() 与 sendHeartbeat() 的返回值中都和 DatanodeCommand 有关，DatanodeCommad 是所有 NameNode 对 DataNode 指令的基类， DatanodeCommand 有个 成员变量 action 为指令编号，其值为 DatanodeProtocol 中的常量值：

```
public interface DatanodeProtocol {
  final static int DNA_UNKNOWN = 0;    // unknown action   
  final static int DNA_TRANSFER = 1;   // transfer blocks to another datanode
  final static int DNA_INVALIDATE = 2; // invalidate blocks
  final static int DNA_SHUTDOWN = 3;   // shutdown node
  final static int DNA_REGISTER = 4;   // re-register
  final static int DNA_FINALIZE = 5;   // finalize previous upgrade
  final static int DNA_RECOVERBLOCK = 6;  // request a block recovery
  final static int DNA_ACCESSKEYUPDATE = 7;  // update access key
  final static int DNA_BALANCERBANDWIDTHUPDATE = 8; // update balancer bandwidth
  final static int DNA_CACHE = 9;      // cache blocks
  final static int DNA_UNCACHE = 10;   // uncache blocks
}
```

> **DatanodeCommand** 有7个子类，代表了不同的操作。

- **BlockCommand** ： 继承了 DatanodeCommand，增加了几个成员变量： 
    - Block[] blocks：包含了此命令涉及的所有数据块
    - DatanodeInfo[][] targets：用于数据块复制或者数据块恢复中，提供了复制或恢复涉及的数据节点信息

##### 6.2.2.1.4 数据块操作相关方法

- **reportBadBlocks()**： HDFS 会在三种情况下通过 CRC-32 进行错误检测： DataNode 接收数据后，存储数据前；客户端读取 DataNode 上的数据时；DataNode 上的 DataBlockScanner 扫描线程定期扫描数据块。当发现数据块有问题时，则会通过此方法上报给 NameNode。
- **blockReceivedAndDeleted()**：DataNode 通过此方法向 NameNode 报告它已经完成数据的接收和删除操作。 
- **commitBlockSynchronization()**： 进行故障恢复过程中涉及的重要方法
- **errorReport()**： 用于 DataNode 向 NameNode 上报运行过程中发生的一些状况，如磁盘不可写、等待被复制的数据块不存在等。


#### 6.2.2.2 InterDatanodeProtocol

> DataNode 与 DataNode 间的接口， 只用于处理异常情况。

> 为 IPC 建立连接是一个开销比较大的操作，在正常的 DataNode 写操作过程中， DataNode 直接不需要通过 IPC 进行交互，但故障发生之后，参与到这个写操作的 DataNodes 中，有一个 DataNode 会被选择出来，协调其他 DataNodes， 进行故障恢复，此过程需要使用到这个 接口。


#### 6.2.2.3 NamenodeProtocol

> SecondaryNameNode 与 NameNode 之间的接口。



## 6.3. 非远程过程调用接口

> HDFS 的文件和目录相关事务操作是基于 IPC 的，但是 HDFS 的数据读写是基于的 TCP 的数据流式访问。

### 6.3.1 DataNode 上的非 IPC 接口

#### 6.3.1.1 DataTransferProtocol


### 6.3.2 NameNode 与 SecondaryNameNode 上的非 IPC 接口


## 6.4. HDFS 主要流程

### 6.4.1 Client 到 NameNode 的元数据操作

```
--> DistributedFileSystem.mkdir()
--- ClientProtocal.mkdir() IPC
```

- mkdir()
> 在目录树数据结构中的对应位置创建新的目录节点，同时记录这个操作并持久化到日志中。


- delete()
> Client 删除文件时，NameNode 会从目录树数据结构中删除对应文件节点，同时记录这个操作并持久化到日志中。但不会主动通知 DataNode 去删除数据文件实体，而是标记操作涉及的需要被删除的数据块，当保存着这些数据块的DataNodes 向 NameNode 发送心跳时，在心跳的应答里，NameNode 会通过 DatanodeCommand 命令 DataNode 删除数据块。 

### 6.4.2 Client 读文件

### 6.4.3 Client 写文件

### 6.4.4 DataNode 到 NameNode 的注册和心跳

### 6.4.5 SecondaryNameNode 合并元数据